# -*- encoding: utf-8 -*-
# @Author: SWHL
# @Contact: liekkaskono@163.com
import importlib
import time
from typing import Dict
import streamlit as st
import json
from utils import logger, make_prompt, read_yaml
from ticket.steps import output

config = read_yaml("config.yaml")

st.set_page_config(
    page_title=config.get("title"),
    page_icon=":robot:",
)

def predict_only_model(text, model):
    # params_dict = st.session_state["params"]
    response = model(text, history=None,)
    print(json.loads(response))
    return json.loads(response)


def bot_print(content, avatar: str = "ğŸ¤–"):
    with st.chat_message("assistant", avatar=avatar):
        message_placeholder = st.empty()
        full_response = ""
        for chunk in content.split('ã€‚'):
            full_response += chunk + "  \n"
            time.sleep(0.05)
            message_placeholder.markdown(full_response + "  \n")
        message_placeholder.markdown(full_response)




def tips(txt: str, wait_time: int = 2, icon: str = "ğŸ‰"):
    st.toast(txt, icon=icon)
    time.sleep(wait_time)


if __name__ == "__main__":
    title = config.get("title")
    version = config.get("version", "0.0.1")
    st.markdown(
        f"<h3 style='text-align: center;'>{title} v{version}</h3><br/>",
        unsafe_allow_html=True,
    )

    llm_module = importlib.import_module("llm")
    llm_params: Dict[str, Dict] = config.get("LLM_API")
    select_model = 'ERNIEBot'
    # menu_col1, menu_col2, menu_col3 = st.columns([1, 1, 1])
    # select_model = menu_col1.selectbox("ğŸ¨LLM:", llm_params.keys())
    # if "ERNIEBot" in select_model:
    #     with st.expander("LLM ErnieBot", expanded=True):
    #         opt_col1, opt_col2 = st.columns([1, 1])
    #         api_type = opt_col1.selectbox(
    #             "API Type(å¿…é€‰)",
    #             options=["aistudio", "qianfan", "yinian"],
    #             help="æä¾›å¯¹è¯èƒ½åŠ›çš„åç«¯å¹³å°",
    #         )
    #         access_token = opt_col2.text_input(
    #             "Access Token(å¿…å¡«) &nbsp;[å¦‚ä½•è·å¾—ï¼Ÿ](https://github.com/PaddlePaddle/ERNIE-Bot-SDK/blob/2520b8d482a36e39fcb2287614197a981ecb6b79/erniebot/docs/authentication.md)",
    #             "",
    #             help="ç”¨äºè®¿é—®åç«¯å¹³å°çš„access tokenï¼ˆå‚è€ƒä½¿ç”¨è¯´æ˜è·å–ï¼‰ï¼Œå¦‚æœè®¾ç½®äº†AKã€SKåˆ™æ— éœ€è®¾ç½®æ­¤å‚æ•°",
    #         )
    #         llm_params[select_model]["api_type"] = api_type
    #
    #         if access_token:
    #             llm_params[select_model]["access_token"] = access_token

    MODEL_OPTIONS = {
        name: getattr(llm_module, name)(**params) for name, params in llm_params.items()
    }



    # with st.expander("ğŸ’¡Prompt", expanded=False):
    #     text_area = st.empty()
    #     input_prompt = text_area.text_area(
    #         label="Input",
    #         max_chars=500,
    #         height=200,
    #         label_visibility="hidden",
    #         value=config.get("DEFAULT_PROMPT"),
    #         key="input_prompt",
    #     )
    bot_print("æˆ‘æ˜¯æ“ä½œç¥¨ç”ŸæˆåŠ©æ‰‹ï¼Œä½ å¯ä»¥è¾“å…¥æ“ä½œä»»åŠ¡å’Œè®¾å¤‡çš„ç›¸å…³ä¿¡æ¯ï¼Œæˆ‘å¸®ä½ ç”Ÿæˆæ“ä½œç¥¨ã€‚ï¼ˆæš‚æ—¶ä»…æ”¯æŒå°åŒºã€æŸ±ä¸Šå¼€å…³ï¼ˆå«è‡ªåŠ¨åŒ–ï¼‰è¿è¡Œè½¬æ£€ä¿®æˆ–æ£€ä¿®è½¬è¿è¡Œï¼‰\n\
              ä¾‹å¦‚ï¼šå°†110kVè¥¿å—ç«™10kvæ–—æ–‡çº¿FA2 #1æ†æµæ²™å…¬ç”¨å°ç”±è¿è¡Œè½¬æ£€ä¿®ï¼Œæœ‰1ä¸ªä½å‹åˆ€é—¸ï¼Œ3ä¸ªä½å‹å¼€å…³")
    input_txt = st.chat_input("é—®ç‚¹å•¥å§ï¼")
    if input_txt:
        with st.chat_message("user", avatar="ğŸ˜€"):
            st.markdown(input_txt)

        llm = MODEL_OPTIONS[select_model]
        input_prompt = config.get("DEFAULT_PROMPT")
        # if not input_prompt:
        #     input_prompt = config.get("DEFAULT_PROMPT")

        # bot_print("ä»çŸ¥è¯†åº“ä¸­æŠ½å–ç»“æœä¸ºç©ºï¼Œç›´æ¥é‡‡ç”¨LLMçš„æœ¬èº«èƒ½åŠ›å›ç­”ã€‚", avatar="ğŸ“„")
        json_results = predict_only_model(input_txt, llm)
        response = output(
            name=json_results.get('è®¾å¤‡åç§°', ''),
            model=json_results.get('è®¾å¤‡ç±»å‹', ''),
            before=json_results.get('æ“ä½œå‰çŠ¶æ€', ''),
            after=json_results.get('æ“ä½œåçŠ¶æ€', ''),
            blade=json_results.get('é«˜å‹åˆ€é—¸æ•°é‡', 1),
            auto=json_results.get('è‡ªåŠ¨åŒ–å¼€å…³', 'false'),
            l_model=json_results.get('å°åŒºä½å‹é…ç½®', ''),
            l_blade=json_results.get('ä½å‹åˆ€é—¸æ•°é‡', 1),
            l_switch=json_results.get('ä½å‹å¼€å…³æ•°é‡', 1),
        )
        str_result = '\n'.join(response)
        # print(str_result)
        bot_print(str_result)
